{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Desafio Quantamental Itaú - 2023</h1>\n",
    "<h3>Lamia - Modelo 03</h3>\n",
    "<h4>NLTK-SentimentIntensityAnalyzer on FinViz.com</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo tem o objetivo de realizar uma análise de sentimento nas ações mais voláteis da bolsa, assim, com notícias boas temos mais chance de faturar um capital maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(ticker):\n",
    "    url = f'https://finviz.com/quote.ashx?t={ticker}'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    news_table = soup.find(id='news-table')\n",
    "    return news_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news(news_table, ticker):\n",
    "    parsed_news = []\n",
    "    \n",
    "    for x in news_table.findAll('tr'):\n",
    "        try:\n",
    "            text = x.a.get_text() \n",
    "            date_scrape = x.td.text.split()\n",
    "\n",
    "            if len(date_scrape) == 1:\n",
    "                time = date_scrape[0]\n",
    "            else:\n",
    "                date = date_scrape[0]\n",
    "                time = date_scrape[1]\n",
    "\n",
    "            parsed_news.append([date, time, ticker, text])        \n",
    "        except:\n",
    "            pass\n",
    "\t\t\t\n",
    "    columns = ['date', 'time', 'ticker', 'headline']\n",
    "    parsed_news_df = pd.DataFrame(parsed_news, columns=columns)        \n",
    "    parsed_news_df['datetime'] = pd.to_datetime(parsed_news_df['date'] + ' ' + parsed_news_df['time'])\n",
    "    return parsed_news_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_news(parsed_news_df):\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    scores = parsed_news_df['headline'].apply(vader.polarity_scores).tolist()\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    parsed_and_scored_news = parsed_news_df.join(scores_df, rsuffix='_right')             \n",
    "    parsed_and_scored_news = parsed_and_scored_news.set_index('datetime')    \n",
    "    parsed_and_scored_news = parsed_and_scored_news.drop(['date', 'time'], 1)          \n",
    "    parsed_and_scored_news = parsed_and_scored_news.rename(columns={\"compound\": \"sentiment_score\"})\n",
    "    return parsed_and_scored_news\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_by_days(tickers):\n",
    "    all_news_df = pd.DataFrame(columns=['date', 'time', 'ticker', 'headline', 'datetime'])\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        news_table = get_news(ticker)\n",
    "        parsed_news_df = parse_news(news_table, ticker)\n",
    "        all_news_df = all_news_df.append(parsed_news_df)\n",
    "        \n",
    "    scored_news_df = score_news(all_news_df)\n",
    "    return scored_news_df.resample('D').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de tickers que você deseja analisar\n",
    "tickers_list = ['AAPL', 'GOOGL', 'MSFT', 'BTCUSD', 'ETHUSD']\n",
    "\n",
    "sentiment_by_days = analyze_sentiment_by_days(tickers_list)\n",
    "print(sentiment_by_days)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
